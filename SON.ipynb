{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chiaraanni/AMD/blob/main/SON.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **ALGORITHM FOR MASSIVE DATA**"
      ],
      "metadata": {
        "id": "xX3wbpVpX_Pn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **MARKET BASKET ANALYSIS**"
      ],
      "metadata": {
        "id": "PiN2WO5eYEt9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Libraries**"
      ],
      "metadata": {
        "id": "RLvC8qAWXSKf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3NIJGhzMtX2s",
        "outputId": "711121f7-49f0-46a4-a8e5-cd5ebb555d50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.1.tar.gz (317.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.0/317.0 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.1-py2.py3-none-any.whl size=317488491 sha256=9d69751eb06967bff0f4281e76299ad228bbe243a491935eafe294eb85afe4a1\n",
            "  Stored in directory: /root/.cache/pip/wheels/80/1d/60/2c256ed38dddce2fdd93be545214a63e02fbd8d74fb0b7f3a6\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.1\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark\n",
        "# Let's intialize the spark context and let's parallelize the data\n",
        "import os\n",
        "import pyspark as spark\n",
        "#import pandas as pd\n",
        "import itertools\n",
        "from pyspark.sql import SparkSession\n",
        "from itertools import combinations\n",
        "import math"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Load the file from Kaggle's link**"
      ],
      "metadata": {
        "id": "c5NQXphDYTPG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vx5oH6rgQ4OS",
        "outputId": "08f00b68-888d-4655-e7a9-73d44c8ae2e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading 1-3m-linkedin-jobs-and-skills-2024.zip to /content\n",
            " 99% 1.87G/1.88G [00:20<00:00, 99.1MB/s]\n",
            "100% 1.88G/1.88G [00:20<00:00, 97.4MB/s]\n"
          ]
        }
      ],
      "source": [
        "os.environ['KAGGLE_USERNAME'] = \"chiaraanni\"\n",
        "os.environ['KAGGLE_KEY'] = \"b5ec3d7be8b44a0db1812ecc93cc48e2\"\n",
        "!kaggle datasets download -d asaniczka/1-3m-linkedin-jobs-and-skills-2024\n",
        "!unzip /content/1-3m-linkedin-jobs-and-skills-2024.zip > /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qx_3sJKquBXn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6cb027f3-b5a7-4516-de9a-2de485cdb03e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1294374"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# Load the file into a dataframe and drop the null values\n",
        "spark = SparkSession.builder.appName(\"MarketBasket\").getOrCreate()\n",
        "\n",
        "path = '/content/job_skills.csv'\n",
        "\n",
        "df= spark.read.options(header=True).csv(path).dropna()\n",
        "df=df.select(df['job_skills']) #select'jobskill\n",
        "df.count()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Sample the dataset**"
      ],
      "metadata": {
        "id": "a2lyZWsGYnJU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df=df.sample(False, 0.002)\n",
        "rdd2=df.rdd\n",
        "splitted_rdd= rdd2.map(lambda row: row['job_skills'].split(', '))\n",
        "rdd_dim=splitted_rdd.count()\n",
        "rdd_dim"
      ],
      "metadata": {
        "id": "to56gcpL5Us7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rdd_dim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FdBTjOqhCWR9",
        "outputId": "304a9b9e-6bc8-4e90-aa2a-eafe78372801"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2615"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_2rZdRVtvkXt",
        "outputId": "4b52cf26-4d26-4383-e302-2b2f08392266"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of partitions before: 6\n",
            "Number of partitions after: 10\n",
            "Support:  52\n",
            "Support for each partition 10\n"
          ]
        }
      ],
      "source": [
        "# Decide the number of partition and the supports\n",
        "\n",
        "num_partitions = splitted_rdd.getNumPartitions()\n",
        "print(\"Number of partitions before:\", num_partitions)\n",
        "partitioned_rdd=splitted_rdd.repartition(10)\n",
        "num_partitions = partitioned_rdd.getNumPartitions()\n",
        "print(\"Number of partitions after:\", num_partitions)\n",
        "\n",
        "support=math.trunc(rdd_dim*2/100)\n",
        "supp_partition=math.trunc(2*support/num_partitions)\n",
        "print(\"Support: \", support)\n",
        "print(\"Support for each partition\", supp_partition)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **SON Algorithm**"
      ],
      "metadata": {
        "id": "H8ssUp9nY2cz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Finding the frequent singletons**"
      ],
      "metadata": {
        "id": "DmpP4jxQY9s0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CPll45O31qf4",
        "outputId": "dd33c26a-566e-4a0d-f142-552a03808437"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Communication', 129),\n",
              " ('Teamwork', 77),\n",
              " ('Leadership', 76),\n",
              " ('Customer service', 51),\n",
              " ('Customer Service', 47),\n",
              " ('Communication skills', 45),\n",
              " ('Problem Solving', 44),\n",
              " ('Communication Skills', 37),\n",
              " ('Nursing', 35),\n",
              " ('Problemsolving', 34),\n",
              " ('Training', 34),\n",
              " ('Project Management', 34),\n",
              " ('Collaboration', 33),\n",
              " ('Microsoft Office Suite', 32),\n",
              " ('Time management', 31)]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# Frequent singletons in all the partitions\n",
        "\n",
        "def first_pass_APriori_partitioned(partitions, supp):\n",
        "    basket_counts = {}\n",
        "    for basket in partitions: # Esegui la logica del primo passaggio APriori per questa partizione\n",
        "        for item in basket:\n",
        "            basket_counts[item] = basket_counts.get(item, 0) + 1\n",
        "\n",
        "    frequent_items = [(item, count) for item, count in basket_counts.items() if count > supp] # Filtra gli elementi con supporto maggiore di `supp`\n",
        "    sorted_frequent_items = sorted(frequent_items, key=lambda x: x[1], reverse=True) # Ordina gli elementi per supporto decrescente\n",
        "    return sorted_frequent_items\n",
        "\n",
        "\n",
        "first_pass_part = splitted_rdd.mapPartitions(lambda partition: first_pass_APriori_partitioned(partition, supp_partition))\n",
        "first_pass_part.take(15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Rg0tqY-52z7",
        "outputId": "d6e70de4-7a6c-41f7-df21-1a53dc754e67"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "We obtained 125 items\n"
          ]
        }
      ],
      "source": [
        "frequent_singletons = set(first_pass_part.map(lambda x:x[0]).collect())\n",
        "print(f\"We obtained {len(frequent_singletons)} items\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eUyh4FWP7nhe",
        "outputId": "e62d902f-43a1-4cd0-f93f-a8964f712e75"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "How many are frequent in all the set?\n",
            "Remaining singleton 70\n",
            "First 15  singleton [('Communication', 742), ('Teamwork', 423), ('Leadership', 381), ('Customer service', 311), ('Customer Service', 227), ('Communication skills', 223), ('Problem Solving', 201), ('Nursing', 197), ('Sales', 188), ('Collaboration', 180), ('Problemsolving', 175), ('Training', 151), ('Communication Skills', 148), ('Project Management', 147), ('Time Management', 141)]\n"
          ]
        }
      ],
      "source": [
        "# Frequent singletons in the entire dataset considered\n",
        "\n",
        "print(\"How many are frequent in all the set?\")\n",
        "def first_pass_APriori(rdd_, freq_set, supp, n_toshow):\n",
        "  first_pass = rdd_.flatMap(lambda basket:[(e,1) for e in basket if e in freq_set]) \\\n",
        "                  .reduceByKey(lambda x,y:x+y) \\\n",
        "                  .filter(lambda x:x[1]>supp) \\\n",
        "                  .sortBy(lambda x: x[1], ascending=False)\n",
        "\n",
        "  print(\"Remaining singleton\", first_pass.count())\n",
        "  print(f\"First {n_toshow}  singleton\", first_pass.take(n_toshow))\n",
        "  return first_pass\n",
        "\n",
        "first_pass=first_pass_APriori(splitted_rdd, frequent_singletons, support, 15)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Finding the frequent couples**"
      ],
      "metadata": {
        "id": "pEGr5432ZQkk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GCBtv2r886i4",
        "outputId": "7135ab7b-a1c5-474e-c272-d1486dc000ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(('Communication', 'Teamwork'), 47), (('Communication', 'Leadership'), 41), (('Communication', 'Problemsolving'), 24), (('Communication', 'Problem Solving'), 22), (('Communication', 'Customer Service'), 19), (('Collaboration', 'Communication'), 18), (('Leadership', 'Teamwork'), 18), (('Communication', 'Time management'), 17), (('Communication', 'Customer service'), 17), (('Communication', 'Sales'), 16), (('Communication', 'Training'), 15), (('Problemsolving', 'Teamwork'), 14), (('Customer Service', 'Teamwork'), 14), (('Communication skills', 'Customer service'), 14), (('Communication Skills', 'Problem Solving'), 14)]\n"
          ]
        }
      ],
      "source": [
        "# Frequent pairs in all the partitions\n",
        "\n",
        "def second_pass_APriori_partitioned(partitions, supp, frequent_set):\n",
        "    basket_counts = {}\n",
        "    for basket in partitions:\n",
        "      tuple_list=list(combinations(sorted(basket),2))\n",
        "      for tuple_ in tuple_list:\n",
        "        if tuple_[0] in frequent_set and tuple_[1] in frequent_set:\n",
        "          basket_counts[tuple_] = basket_counts.get(tuple_, 0) + 1\n",
        "\n",
        "    frequent_items = [(item, count) for item, count in basket_counts.items() if count > supp] # Filtra gli elementi con supporto maggiore di `supp`\n",
        "    sorted_frequent_items = sorted(frequent_items, key=lambda x: x[1], reverse=True) # Ordina gli elementi per supporto decrescente\n",
        "    return sorted_frequent_items\n",
        "\n",
        "second_pass_part = splitted_rdd.mapPartitions(lambda partition: second_pass_APriori_partitioned(partition, supp_partition, frequent_singletons))\n",
        "#print(second_pass_part.count())\n",
        "print(second_pass_part.take(15))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cGGw8DDVCnPP",
        "outputId": "684a0a47-91c2-49cc-fbe6-8fa8a035ce17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "We obtained 111 couple\n"
          ]
        }
      ],
      "source": [
        "frequent_couples = set(second_pass_part.map(lambda x:x[0]).collect())\n",
        "print(f\"We obtained {len(frequent_couples)} couple\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HRUU-t5XOD-W",
        "outputId": "fd6914c4-caf8-4787-ac5e-661daf8df4c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "How many are frequent in all the set?\n",
            "Remaining couples 50\n",
            "First 7  couples [(('Communication', 'Teamwork'), 275), (('Communication', 'Leadership'), 249), (('Communication', 'Customer service'), 150), (('Communication', 'Problem Solving'), 128), (('Communication', 'Customer Service'), 123), (('Communication', 'Problemsolving'), 123), (('Communication', 'Sales'), 123)]\n"
          ]
        }
      ],
      "source": [
        "# Frequent pairs in the entire dataset considered\n",
        "\n",
        "print(\"How many are frequent in all the set?\")\n",
        "def second_pass_APriori(rdd_, frequent_couple, supp, n_toshow):\n",
        "  second_pass = rdd_.flatMap(lambda basket:[(e,1) for e in combinations(sorted(basket),2) if e in frequent_couples]) \\\n",
        "                  .reduceByKey(lambda x,y: x+y) \\\n",
        "                  .filter(lambda x:x[1]>supp)\\\n",
        "                  .sortBy(lambda x: x[1], ascending=False)\n",
        "\n",
        "  print(\"Remaining couples\", second_pass.count())\n",
        "  print(f\"First {n_toshow}  couples\", second_pass.take(n_toshow))\n",
        "  return second_pass\n",
        "\n",
        "second_pass=second_pass_APriori(splitted_rdd, frequent_couples, support, 7)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Finding the generalized frequent itemsets**"
      ],
      "metadata": {
        "id": "CnUIwklYZnOL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AbgpB3yz2vvj"
      },
      "outputs": [],
      "source": [
        "# Frequent itemests in all the partitions\n",
        "\n",
        "def generalized_pass_APriori_partitioned(partitions, supp, frequent_set, pass_):\n",
        "    basket_counts = {}\n",
        "    for basket in partitions:\n",
        "      tuple_list=list(combinations(sorted(basket),pass_))\n",
        "      for tuple_ in tuple_list:\n",
        "        if all(item in frequent_set for item in list(combinations(sorted(tuple_),pass_-1))):\n",
        "          basket_counts[tuple_] = basket_counts.get(tuple_, 0) + 1\n",
        "\n",
        "    frequent_items = [(item, count) for item, count in basket_counts.items() if count > supp] # Filtra gli elementi con supporto maggiore di `supp`\n",
        "    #sorted_frequent_items = sorted(frequent_items, key=lambda x: x[1], reverse=True) # Ordina gli elementi per supporto decrescente\n",
        "    return frequent_items"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KEVnLsdXmEMN",
        "outputId": "2c613f8d-c520-4e14-926b-3a175bd45376"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is the 3 pass\n",
            "The frequent set is: \n",
            "[(('Communication', 'Problemsolving', 'Teamwork'), 12), (('Communication', 'Customer Service', 'Teamwork'), 12), (('Communication', 'Problem Solving', 'Teamwork'), 13), (('Communication', 'Leadership', 'Teamwork'), 14), (('Communication', 'Customer service', 'Teamwork'), 15), (('Communication', 'Customer service', 'Time management'), 12), (('Communication', 'Flexibility', 'Teamwork'), 12), (('Customer service', 'Teamwork', 'Time management'), 11), (('Attention to detail', 'Communication', 'Customer service'), 13), (('Communication', 'Teamwork', 'Time Management'), 12), (('Attention to detail', 'Communication', 'Problemsolving'), 11), (('Attention to detail', 'Customer service', 'Problemsolving'), 12), (('Communication', 'Customer service', 'Problemsolving'), 18), (('Communication', 'Customer service', 'Inventory management'), 11), (('Communication', 'Leadership', 'Problem Solving'), 23)]\n",
            "We obtained 44 itemsets\n",
            "How many are frequent in all the set?\n",
            "Remaining itemsets:  7\n",
            "First 15  items [(('Communication', 'Leadership', 'Problem Solving'), 62), (('Collaboration', 'Communication', 'Leadership'), 57), (('Communication', 'Problem Solving', 'Teamwork'), 72), (('Communication', 'Customer service', 'Teamwork'), 55), (('Communication', 'Leadership', 'Teamwork'), 101), (('Communication', 'Problemsolving', 'Teamwork'), 68), (('Communication', 'Customer Service', 'Teamwork'), 66)]\n",
            "This is the 4 pass\n",
            "The frequent set is: \n",
            "[(('Communication', 'Leadership', 'Problem Solving', 'Teamwork'), 11), (('Adaptability', 'Collaboration', 'Communication', 'Problem Solving'), 27), (('Collaboration', 'Communication', 'Leadership', 'Problem Solving'), 26), (('Communication', 'Customer Service', 'Problem Solving', 'Teamwork'), 15), (('Communication', 'Customer Service', 'Problem Solving', 'Time Management'), 11), (('Customer Service', 'Problem Solving', 'Teamwork', 'Time Management'), 11)]\n",
            "We obtained 6 itemsets\n",
            "How many are frequent in all the set?\n",
            "Remaining itemsets:  0\n",
            "First 15  items []\n"
          ]
        }
      ],
      "source": [
        "# Frequent itemsets in the entire dataset considered\n",
        "\n",
        "count=1\n",
        "frequent_set=frequent_couples\n",
        "pass_=3\n",
        "\n",
        "while count>0:\n",
        "\n",
        "  print(f\"This is the {pass_} pass\")\n",
        "  generalized_pass_part = splitted_rdd.mapPartitions(lambda partition: generalized_pass_APriori_partitioned(partition, supp_partition, frequent_set, pass_))\n",
        "  print(\"The frequent set is: \")\n",
        "  print(generalized_pass_part.take(15))\n",
        "  frequent_set = set(generalized_pass_part.map(lambda x:x[0]).collect())\n",
        "\n",
        "  print(f\"We obtained {len(frequent_set)} itemsets\")\n",
        "\n",
        "  print(\"How many are frequent in all the set?\")\n",
        "  frdd = splitted_rdd.flatMap(lambda basket: [(e,1) for e in combinations(sorted(basket),pass_) if e in frequent_set])\\\n",
        "              .reduceByKey(lambda x,y:x+y) \\\n",
        "              .filter(lambda x:x[1] > support)\n",
        "\n",
        "  count=frdd.count()\n",
        "  print(\"Remaining itemsets: \", count)\n",
        "  print(f\"First 15  items\", frdd.take(15))\n",
        "  pass_ +=1\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMPPB6EJ82MbSwcy3OxNu4l",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}